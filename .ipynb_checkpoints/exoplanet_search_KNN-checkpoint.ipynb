{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanets = pd.read_csv(os.path.join('Resources', 'cumulative.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "exoplanets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least for now: keeping all columns in case of later interest, but removing derived columns from predictions\n",
    "\n",
    "Evaluations for comparison: koi_pdisposition (use only rows where value is FALSE POSITIVE or CANDIDATE, since others (mostly?) have incomplete data); koi_score\n",
    "\n",
    "ID to use: kepoi_name\n",
    "ID columns to ignore: kepid, kepler_name, rowid\n",
    "Evaluations to ignore (for now): koi_disposition, koi_vet_stat, koi_vet_date, koi_disp_prov, koi_comment, koi_fittype, k_limbdark_mod, koi_parm_prov, koi_time0 (same info as koi_time0bk), koi_fittype (describes analytical methods - might be related to other variablesbut secondary), koi_limbdark_mod\t(describes analytical method)\n",
    "koi_ldm_coeff1, koi_ldm_coeff2, koi_ldm_coeff3, koi_ldm_coeff4 (fitted parameters...)\n",
    "koi_tce_plnt_num, koi_tce_delivname, koi_quarters\n",
    "koi_trans_mod, koi_model_dof\n",
    "koi_datalink_dvr, koi_datalink_dvs\t\n",
    "koi_ror, koi_prad ... are calculated, but kept it in for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows (if any) where koi_pdisposition is not FALSE POSITIVE or CANDIDATE; koi_disposition has additional categories\n",
    "exoplanets.koi_pdisposition.unique()\n",
    "#None found in current file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make koi_pdisposition and koi_disposition numerical variables, see if they are the same (no, )\n",
    "exoplanets_pdisp_cat = pd.get_dummies(exoplanets, prefix=['koi_pdisposition'], columns=['koi_pdisposition'])\n",
    "#\n",
    "exoplanets_pdisp_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanets_disp_cat = pd.get_dummies(exoplanets_pdisp_cat, prefix=['koi_disposition'], columns=['koi_disposition'])\n",
    "exoplanets_disp_cat.drop('koi_pdisposition_FALSE POSITIVE', axis=1, inplace=True)\n",
    "\n",
    "exoplanets_disp_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to drop koi_pdisposition_CANDIDATE\n",
    "For a basic set: X = exoplanets_disp_cat[[\"koi_fpflag_nt\", \"koi_fpflag_ss\", \"koi_fpflag_co\", \"koi_fpflag_ec\", \"koi_period\", \"koi_time0bk\", \"koi_impact\",\"koi_duration\", \"koi_depth\", \"koi_prad\", \"koi_teq\", \"koi_insol\", \"koi_model_snr\", \"koi_steff\", \"koi_slogg\", \"koi_srad\", \"ra\", \"dec\", \"koi_kepmag\"]]\n",
    "\n",
    "For basic set, drop (\"rowid\", \"kepid\", \"kepoi_name\", \"kepler_name\", \"koi_score\", \"koi_period_err1\", \"koi_period_err2\", \"koi_time0bk_err1\", \"koi_time0bk_err2\", \"koi_impact_err1\", \"koi_impact_err2\", \"koi_duration_err1\", \"koi_duration_err2\", \"koi_depth_err1\", \"koi_depth_err2\", \"koi_prad_err1\", \"koi_prad_err2\", \"koi_teq_err1\", \"koi_teq_err2\", \"koi_insol_err1\", \"koi_insol_err2\", \"koi_tce_plnt_num\", \"koi_tce_delivname\",\"koi_steff_err1\", \"koi_steff_err2\", \"koi_slogg_err1\", \"koi_slogg_err2\", \"koi_srad_err1\", \"koi_srad_err2\", \"koi_disposition_CANDIDATE\", \"koi_disposition_CONFIRMED\", \"koi_disposition_FALSE POSITIVE\")\n",
    "\n",
    "y = exoplanets_disp_cat[[koi_pdisposition_CANDIDATE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanets_basic = exoplanets_disp_cat.drop([\"rowid\", \"kepoi_name\", \"kepler_name\", \"koi_score\", \"koi_period_err1\", \"koi_period_err2\", \"koi_time0bk_err1\", \"koi_time0bk_err2\", \"koi_impact_err1\", \"koi_impact_err2\", \"koi_duration_err1\", \"koi_duration_err2\", \"koi_depth_err1\", \"koi_depth_err2\", \"koi_prad_err1\", \"koi_prad_err2\", \"koi_teq_err1\", \"koi_teq_err2\", \"koi_insol_err1\", \"koi_insol_err2\", \"koi_tce_plnt_num\", \"koi_tce_delivname\",\"koi_steff_err1\", \"koi_steff_err2\", \"koi_slogg_err1\", \"koi_slogg_err2\", \"koi_srad_err1\", \"koi_srad_err2\", \"koi_disposition_CANDIDATE\", \"koi_disposition_CONFIRMED\", \"koi_disposition_FALSE POSITIVE\"], axis=1)\n",
    "exoplanets_basic.dropna(axis=0)\n",
    "#None found\n",
    "#https://stackoverflow.com/questions/31323499/sklearn-error-valueerror-input-contains-nan-infinity-or-a-value-too-large-for\n",
    "#exoplanets_basic = exoplanets_basic.reset_index()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(exoplanets_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isfinite(exoplanets_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanets_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = exoplanets_basic.drop(\"koi_pdisposition_CANDIDATE\", axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data using the X_scaler and y_scaler models\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that k: 13 seems to be the best choice for this dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=13 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
