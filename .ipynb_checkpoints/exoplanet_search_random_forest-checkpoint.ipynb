{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import some dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanets = pd.read_csv(os.path.join('Resources', 'cumulative.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "exoplanets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows (if any) where koi_pdisposition is not FALSE POSITIVE or CANDIDATE; koi_disposition has additional categories\n",
    "exoplanets.koi_pdisposition.unique()\n",
    "#None found in current file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make koi_pdisposition and koi_disposition numerical variables, see if they are the same (no, koi_disposition has more categories)\n",
    "exoplanets_pdisp_cat = pd.get_dummies(exoplanets, prefix=['koi_pdisposition'], columns=['koi_pdisposition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanets_disp_cat = pd.get_dummies(exoplanets_pdisp_cat, prefix=['koi_disposition'], columns=['koi_disposition'])\n",
    "exoplanets_disp_cat.drop('koi_pdisposition_FALSE POSITIVE', axis=1, inplace=True)\n",
    "\n",
    "exoplanets_disp_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop error columns (although these could be useful in the real world), extra IDs, KOI score, \n",
    "#and extra evaluation columns\n",
    "exoplanets_basic = exoplanets_disp_cat.drop([\"rowid\", \"kepoi_name\", \"kepler_name\", \"koi_score\", \n",
    "                                             \"koi_period_err1\", \"koi_period_err2\", \"koi_time0bk_err1\", \n",
    "                                             \"koi_time0bk_err2\", \"koi_impact_err1\", \"koi_impact_err2\", \n",
    "                                             \"koi_duration_err1\", \"koi_duration_err2\", \"koi_depth_err1\", \n",
    "                                             \"koi_depth_err2\", \"koi_prad_err1\", \"koi_prad_err2\", \"koi_teq_err1\", \n",
    "                                             \"koi_teq_err2\", \"koi_insol_err1\", \"koi_insol_err2\", \"koi_tce_plnt_num\", \n",
    "                                             \"koi_tce_delivname\",\"koi_steff_err1\", \"koi_steff_err2\", \n",
    "                                             \"koi_slogg_err1\", \"koi_slogg_err2\", \"koi_srad_err1\", \"koi_srad_err2\", \n",
    "                                             \"koi_disposition_CANDIDATE\", \"koi_disposition_CONFIRMED\", \n",
    "                                             \"koi_disposition_FALSE POSITIVE\"], axis=1)\n",
    "exoplanets_basic.rename(columns={'koi_fpflag_nt': 'flag_not_transit_like', \n",
    "                   'koi_fpflag_ss': 'flag_stellar_eclipse', \n",
    "                   'koi_fpflag_co': 'flag_centroid_offset',\n",
    "                   'koi_fpflag_ec': 'flag_ephemeris match',                  \n",
    "                   'koi_period': 'orbital_period',                  \n",
    "                   'koi_time0bk': 'time_first_trans_detected',\n",
    "                   'koi_impact': 'star_planet_dist_at_conj',                   \n",
    "                   'koi_duration': 'trans_duration',                   \n",
    "                   'koi_depth': 'stellar_flux_loss_at_trans_min',\n",
    "                   'koi_prad': 'planet_radius',\n",
    "                   'koi_teq': 'approx_planet_temp',\n",
    "                   'koi_insol': 'insolation_flux',\n",
    "                   'koi_model_snr': 'trans_sig_to_noise',\n",
    "                   'koi_steff': 'stellar_eff_temp',\n",
    "                   'koi_slogg': 'stellar_surf_gravity',\n",
    "                   'koi_srad': 'stellar_photosph_rad',\n",
    "                   'ra': 'sky_location_right_asc',\n",
    "                   'dec': 'sky_location_declination',                   \n",
    "                   'koi_kepmag': 'stellar_magnitude'}, inplace=True)\n",
    "exoplanets_basic.dropna(axis=0)\n",
    "#No na found by this method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(exoplanets_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isfinite(exoplanets_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/31323499/sklearn-error-valueerror-input-contains-nan-infinity-or-a-value-too-large-for\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "clean_dataset(exoplanets_basic)\n",
    "exoplanets_basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(exoplanets_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isfinite(exoplanets_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree, random state=57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = exoplanets_basic.drop([\"koi_pdisposition_CANDIDATE\", \"kepid\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apparently quite accurate, but included \"flag\" columns, which are scores themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree, random state=57, \"flag\" variables removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_deflag = exoplanets_basic.drop([\"kepid\", 'flag_not_transit_like','flag_centroid_offset','flag_stellar_eclipse','flag_ephemeris match' ], axis=1)\n",
    "data_deflag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_deflag.drop([\"koi_pdisposition_CANDIDATE\"], axis=1)\n",
    "feature_names = data.columns\n",
    "target = data_deflag[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score without \"flag\" columns is lower, but still I guess respectable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier: Some naive parameter adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest, all columns, random state = 57, n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]\n",
    "data = exoplanets_basic.drop([\"koi_pdisposition_CANDIDATE\", \"kepid\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excellent match to Kepler classification - but note 4 of the top 5 predictors are \"flag\" columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with \"flag\" variables removed; random state=57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_deflag.drop([\"koi_pdisposition_CANDIDATE\"], axis=1)\n",
    "feature_names = data.columns\n",
    "target = data_deflag[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep same random state as above\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_deflag, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even better match (at least in this particular run) when flag variables removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest, all columns; random state=57; n_estimators=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exoplanets_basic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d6f0b80b4621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexoplanets_basic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"koi_pdisposition_CANDIDATE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"False_positive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Candidate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexoplanets_basic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"koi_pdisposition_CANDIDATE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kepid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exoplanets_basic' is not defined"
     ]
    }
   ],
   "source": [
    "target = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]\n",
    "data = exoplanets_basic.drop([\"koi_pdisposition_CANDIDATE\", \"kepid\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very slightly lower score than with 200 estimators; relative factor importances quite similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest , all columns; random state=57; n_estimators=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]\n",
    "data = exoplanets_basic.drop([\"koi_pdisposition_CANDIDATE\", \"kepid\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very slightly lower score than with 200 estimators; relative factor importances quite similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest, all columns, random state = 312, n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]\n",
    "data = exoplanets_basic.drop([\"koi_pdisposition_CANDIDATE\", \"kepid\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No major changes with choice of random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier: Additional parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure how much this matters given the already high scores, but easy enough to test\n",
    "Some possibly useful choices from scikit-learn.org (based on limited understanding!):\n",
    "\n",
    "criterion{“gini”, “entropy”}, default=”gini”\n",
    "https://towardsdatascience.com/gini-index-vs-information-entropy-7a7e4fed3fcb: :entropy might give sharper delineation\n",
    "\n",
    "\n",
    "max_features{“auto”, “sqrt”, “log2”}, int or float, default=”auto”\n",
    "If “auto”, then max_features=sqrt(n_features).\n",
    "If “log2”, then max_features=log2(n_features).\n",
    ">>If None, then max_features=n_features.\n",
    "Note: the search for a split does not stop until at least one valid partition of the node samples is found\n",
    "Increasing features considered at each step might affect results (and run time of course), assuming not already at max.\n",
    "\n",
    "oob_scorebool, default=False\n",
    "https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710\n",
    "Apparently best for small datasets, which ours is not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest, all columns, random state = 57, n_estimators = 200, criterion = \"entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]\n",
    "data = exoplanets_basic.drop([\"koi_pdisposition_CANDIDATE\", \"kepid\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, criterion='entropy')\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest, all columns, random state = 57, n_estimators = 200, max_features='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = exoplanets_basic[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]\n",
    "data = exoplanets_basic.drop([\"koi_pdisposition_CANDIDATE\", \"kepid\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, max_features='auto')\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with \"flag\" variables removed; random state = 57, n_estimators = 200, criterion = \"entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_deflag.drop([\"koi_pdisposition_CANDIDATE\"], axis=1)\n",
    "feature_names = data.columns\n",
    "target = data_deflag[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, criterion='entropy')\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with \"flag\" variables removed; random state = 57, n_estimators = 200, max_features='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_deflag.drop([\"koi_pdisposition_CANDIDATE\"], axis=1)\n",
    "feature_names = data.columns\n",
    "target = data_deflag[\"koi_pdisposition_CANDIDATE\"]\n",
    "target_names = [\"False_positive\", \"Candidate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, max_features='auto')\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
